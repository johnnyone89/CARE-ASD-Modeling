{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE-b_3JwuKTs"
      },
      "outputs": [],
      "source": [
        "# Install PyCaret\n",
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pycaret.classification import *\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "0INpSxJrZzss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload and load dataset\n",
        "print(\"Please upload your dataset (e.g., 'ASD_Traits_Study_Data.csv').\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_path = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "uHc8qbHZZ0gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define target variable and feature cases\n",
        "target = 'ASD_traits'\n",
        "feature_cases = {\n",
        "    \"Minimal Feature Set\": ['SRS', 'CARS', 'AQ10'],\n",
        "    \"Binary Diagnostic Variables\": ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10'],\n",
        "    \"Behavioral and Diagnostic Scores\": ['SRS', 'CARS', 'AQ10'],\n",
        "    \"Demographic Features Only\": ['Gender', 'Age_Years', 'Ethnicity', 'Family_mem_with_ASD', 'Rater'],\n",
        "    \"Combination of Key Groups\": ['Gender', 'Age_Years', 'Ethnicity', 'Family_mem_with_ASD', 'Rater', 'SRS', 'CARS', 'AQ10'],\n",
        "    \"Full Feature Set\": ['Gender', 'Age_Years', 'Ethnicity', 'Family_mem_with_ASD', 'Rater',\n",
        "                         'SRS', 'CARS', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'AQ10']\n",
        "}"
      ],
      "metadata": {
        "id": "STTL6NTRZ66i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split dataset into training and testing sets\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "test_data = pd.concat([X_test, y_test], axis=1)"
      ],
      "metadata": {
        "id": "7zfZuDQcZ85L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Perform PyCaret setup and model comparison for each case\n",
        "case_results = {}\n",
        "\n",
        "for case_name, features in feature_cases.items():\n",
        "    print(f\"Processing Case: {case_name}\")\n",
        "\n",
        "    # Filter training data for the current feature set\n",
        "    case_train_data = train_data[features + [target]]\n",
        "\n",
        "    # PyCaret setup with consistent session ID\n",
        "    clf_setup = setup(\n",
        "        data=case_train_data,\n",
        "        target=target,\n",
        "        session_id=42,  # Ensure reproducibility\n",
        "        fold=5,         # Fivefold cross-validation\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Compare models and select the best one\n",
        "    best_model = compare_models(n_select=1)  # Select only the best model\n",
        "    print(f\"Best Model for {case_name}: {best_model}\")\n",
        "\n",
        "    # Finalize the best model on the entire training data\n",
        "    final_model = finalize_model(best_model)\n",
        "\n",
        "    # Evaluate the finalized model on the test set\n",
        "    case_test_data = test_data[features + [target]]\n",
        "    predictions = predict_model(final_model, data=case_test_data)\n",
        "\n",
        "    # Extract true labels and predictions\n",
        "    y_true = case_test_data[target]\n",
        "    y_pred = predictions['prediction_label']\n",
        "    y_prob = predictions['prediction_score']\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    metrics = {\n",
        "        'Best Model': str(best_model),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'F1-Score': f1_score(y_true, y_pred),\n",
        "        'ROC-AUC': roc_auc_score(y_true, y_prob),\n",
        "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
        "        'Cohen Kappa': cohen_kappa_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "    # Store results for the current case\n",
        "    case_results[case_name] = metrics"
      ],
      "metadata": {
        "id": "uaBW2S4DZ_a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Summarize Results and Save to File\n",
        "results_df = pd.DataFrame(case_results).T\n",
        "print(\"\\nSummary of Results Across All Cases:\")\n",
        "print(results_df)\n",
        "\n",
        "results_df.to_csv('ablation_study_results.csv', index=True)\n",
        "print(\"\\nResults saved to 'ablation_study_results.csv'.\")"
      ],
      "metadata": {
        "id": "9pIjQT6EamkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, call models() to list all available models\n",
        "all_models = models()\n",
        "print(all_models)"
      ],
      "metadata": {
        "id": "iyDg6fUptIZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}